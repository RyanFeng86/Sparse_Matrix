1. These two weeks, I read the websites you sent to me. And I have modified our code to get the correct timing result. And I am trying to use cuSPARAELt to test their tool. I think we can discuss it to determine whether it's necessary.

2. The first link mainly talks about how to use the cuSPAELt and its working principle. First, we need to understand the basics of GEMM. The format is showing here. It should have two numbers which are alpha and beta here. And first multiplier A, and second multiplier B. This blog has simplified this and only considers A multiply B. Moreover, we should keep in mind that A has M rows and K columns. B has K rows and N columns. The result C has M rows and N columns. 

3. Nvidia has developed the cuSPARSELt workflow, which is derived from cuBLASLt and cuTENSOR. This blog tells how to download and use it, but I think right now What we should keep in mind is that this workflow is used to calculate the sparse matrix multiplication and its general idea is shown in the paper.

4. Using this tool, they calculate the general matrix multiplication. Based on the different matrix sizes, they draw serval figures. For example, the first figure's A and B consist of 16-bit float point digits. The x-direction represents them and the n size of matrix A and B.  The Y-direction is the speedup of sparse multiplication and dense multiplication. As shown here, sparse multiplication is always more than 1.5 times faster than dense multiplication. There is two different amount this four-figure. Matrix's digit types and the size of A and B. So according to their result, the way they deal with sparse matrix multiplication takes less time than the normal matrix multiplication.

5. They also test it on different layers. The speedup result is shown here.

6. Another link actually focuses on other aspects. I think such a long article only says one thing. First, it gives us advice on how to determine the matrix size and tile size when we are doing large matrix multiplication on GPU. About the matrix size. First of all, the matrix dimension to be multiples of 16 bytes, otherwise try to be the power of 2. Cause it will run more efficiently on their tools.(cuBLAS 10.2 and cuBLAS 11.0). As for the tile size, the size is better to be the factor of the matrix size. Otherwise, it needs more memory access and causes less reuse of memory. For example, if the tile size is 128x128 and the matrix is 256x256, the matrix can be divided into separate parts. But if the matrix has 256 columns then 6 parts are needed. 

7. And this is the last slide, I have modified our code's timer. After reading many links I found out that there is a special timer which is provided by Cuda called cudaEventRecord. I think this might be the better timer, cause the previous timer that I use originates from window lib, which might not accurate, even more, the previous timer might not be able to time the GPU time. The result is shown here. As you can see, with matrix size increases the time that is consumed nearly always increases. And at the beginning, the improved one uses nearly the same time compared to the normal one. But when the matrix becomes bigger and bigger the improved one is much better than the normal one.